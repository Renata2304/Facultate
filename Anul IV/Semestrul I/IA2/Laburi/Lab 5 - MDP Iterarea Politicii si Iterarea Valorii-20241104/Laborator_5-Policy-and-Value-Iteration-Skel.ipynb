{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/cs-pub-ro/ML/blob/master/lab/lab6/Laborator_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_3a1x3D2pJlE"
   },
   "source": [
    "# Învățare Automată\n",
    "# Învățare prin Recompensă - rezolvarea proceselor de decizie Markov prin tehnici de programare dinamică (Value Iteration, Policy Iteration)\n",
    "### Autori:\n",
    "* Tudor Berariu - 2018\n",
    "* Alexandru Sorici - 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V6-C84FKpUfB"
   },
   "source": [
    "## 1. Scopul laboratorului"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nTKbkxAwpYhl"
   },
   "source": [
    "Scopul laboratorului îl reprezintă înțelegerea conceptelor de proces markov de decizie (MDP), politică, valoare de stare, precum și implementarea unor metode de programare dinamică pentru rezolvarea problemei de control a unui MDP.\n",
    "\n",
    "În cadrul laboratorului veți:\n",
    "- implementa algoritmul de iterare a politicilor\n",
    "- implementa algoritmul de iterare a valorilor de stare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8i_6oVDI-zp5"
   },
   "source": [
    "## 2. Workspace setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PTs6cwy5_Na7"
   },
   "source": [
    "### Câteva bibioteci de care vom avea nevoie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F6Y6WMfQ_R5L"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os.path\n",
    "from argparse import ArgumentParser\n",
    "from copy import copy\n",
    "from random import choice\n",
    "\n",
    "from typing import Dict, List, Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UhMSc8oHEdLK"
   },
   "source": [
    "### Definirea unui labirint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "09ToJHh-Ef2S"
   },
   "outputs": [],
   "source": [
    "class Maze:\n",
    "\n",
    "    NORTH, EAST, SOUTH, WEST = 0, 1, 2, 3  # actions\n",
    "\n",
    "    DYNAMICS = {  # the stochastic effects of actions\n",
    "        NORTH: {(0, -1): 0.1, (-1, 0): .8, (0, 1): .1},\n",
    "        EAST: {(-1, 0): 0.1, (0, 1): .8, (1, 0): .1},\n",
    "        SOUTH: {(0, 1): 0.1, (1, 0): .8, (0, -1): .1},\n",
    "        WEST: {(1, 0): 0.1, (0, -1): .8, (-1, 0): .1},\n",
    "    }\n",
    "\n",
    "    WALL, EMPTY = \"x\", \" \"\n",
    "\n",
    "    VISUALS = {\n",
    "        (0, 0, 1, 1): \"\\N{BOX DRAWINGS HEAVY DOWN AND RIGHT}\",\n",
    "        (1, 0, 0, 1): \"\\N{BOX DRAWINGS HEAVY DOWN AND LEFT}\",\n",
    "        (1, 0, 1, 0): \"\\N{BOX DRAWINGS HEAVY HORIZONTAL}\",\n",
    "        (0, 1, 1, 0): \"\\N{BOX DRAWINGS HEAVY UP AND RIGHT}\",\n",
    "        (1, 1, 0, 0): \"\\N{BOX DRAWINGS HEAVY UP AND LEFT}\",\n",
    "        (0, 1, 0, 1): \"\\N{BOX DRAWINGS HEAVY VERTICAL}\",\n",
    "        (1, 1, 1, 1): \"\\N{BOX DRAWINGS HEAVY VERTICAL AND HORIZONTAL}\",\n",
    "        (1, 1, 1, 0): \"\\N{BOX DRAWINGS HEAVY UP AND HORIZONTAL}\",\n",
    "        (1, 1, 0, 1): \"\\N{BOX DRAWINGS HEAVY VERTICAL AND LEFT}\",\n",
    "        (1, 0, 1, 1): \"\\N{BOX DRAWINGS HEAVY DOWN AND HORIZONTAL}\",\n",
    "        (0, 1, 1, 1): \"\\N{BOX DRAWINGS HEAVY VERTICAL AND RIGHT}\",\n",
    "        (1, 0, 0, 0): \"\\N{BOX DRAWINGS HEAVY LEFT}\",\n",
    "        (0, 1, 0, 0): \"\\N{BOX DRAWINGS HEAVY UP}\",\n",
    "        (0, 0, 1, 0): \"\\N{BOX DRAWINGS HEAVY RIGHT}\",\n",
    "        (0, 0, 0, 1): \"\\N{BOX DRAWINGS HEAVY DOWN}\",\n",
    "        (0, 0, 0, 0): \"\\N{BOX DRAWINGS HEAVY VERTICAL AND HORIZONTAL}\",\n",
    "        WEST: \"\\N{LEFTWARDS ARROW}\",\n",
    "        NORTH: \"\\N{UPWARDS ARROW}\",\n",
    "        EAST: \"\\N{RIGHTWARDS ARROW}\",\n",
    "        SOUTH: \"\\N{DOWNWARDS ARROW}\",\n",
    "    }\n",
    "\n",
    "    def __init__(self, map_name):\n",
    "        self._rewards, self._cells = {}, []\n",
    "        with open(os.path.join(\"maps\", map_name), \"r\") as map_file:\n",
    "            for line in map_file.readlines():\n",
    "                if \":\" in line:\n",
    "                    name, value = line.strip().split(\":\")\n",
    "                    self._rewards[name] = float(value)\n",
    "                else:\n",
    "                    self._cells.append(list(line.strip()))\n",
    "        self._states = [(i, j) for i, row in enumerate(self._cells)\n",
    "                        for j, cell in enumerate(row) if cell != Maze.WALL]\n",
    "\n",
    "    @property\n",
    "    def actions(self):\n",
    "        return [Maze.NORTH, Maze.EAST, Maze.SOUTH, Maze.WEST]\n",
    "\n",
    "    @property\n",
    "    def states(self):\n",
    "        return copy(self._states)\n",
    "\n",
    "    def is_final(self, state):\n",
    "        row, col = state\n",
    "        return self._cells[row][col] != Maze.EMPTY\n",
    "\n",
    "    def effects(self, state, action):\n",
    "        if self.is_final(state):\n",
    "            return []\n",
    "        row, col = state\n",
    "        next_states = {}\n",
    "        for (d_row, d_col), prob in Maze.DYNAMICS[action].items():\n",
    "            next_row, next_col = row + d_row, col + d_col\n",
    "            if self._cells[next_row][next_col] == Maze.WALL:\n",
    "                next_row, next_col = row, col\n",
    "            if (next_row, next_col) in next_states:\n",
    "                prev_prob, _ = next_states[(next_row, next_col)]\n",
    "                prob += prev_prob\n",
    "            cell = self._cells[next_row][next_col]\n",
    "            reward = self._rewards[\"default\" if cell == Maze.EMPTY else cell]\n",
    "            next_states[(next_row, next_col)] = (prob, reward)\n",
    "        return [(s, p, r) for s, (p, r) in next_states.items()]\n",
    "\n",
    "    def print_policy(self, policy):\n",
    "        last_row = []\n",
    "        height = len(self._cells)\n",
    "\n",
    "        for row, row_cells in enumerate(self._cells):\n",
    "            width = len(row_cells)\n",
    "            for col, cell in enumerate(row_cells):\n",
    "                if cell == Maze.WALL:\n",
    "                    north, south, west, east = 0, 0, 0, 0\n",
    "                    if last_row and len(last_row) > col:\n",
    "                        north = last_row[col] == Maze.WALL\n",
    "                    if row + 1 < height:\n",
    "                        south = self._cells[row + 1][col] == Maze.WALL\n",
    "                    if col > 0:\n",
    "                        west = row_cells[col - 1] == Maze.WALL\n",
    "                    if col + 1 < width:\n",
    "                        east = row_cells[col + 1] == Maze.WALL\n",
    "                    sys.stdout.write(Maze.VISUALS[(west, north, east, south)])\n",
    "                elif self.is_final((row, col)):\n",
    "                    sys.stdout.write(cell)\n",
    "                else:\n",
    "                    action = policy[(row, col)]\n",
    "                    sys.stdout.write(Maze.VISUALS[action])\n",
    "            sys.stdout.write(\"\\n\")\n",
    "            last_row = row_cells\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    def print_values(self, v):\n",
    "        for r, row_cells in enumerate(self._cells):\n",
    "            print(\" | \".join([\"%5.2f\" % v[(r, c)] if cell == Maze.EMPTY else \"     \"\n",
    "                              for c, cell in enumerate(row_cells)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u-G9p2SH-r0V"
   },
   "source": [
    "## Cerințe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAP_NAME = 'complex'  #@param ['simple', 'complex', 'be_careful', 'suffer']\n",
    "gamma = 0.9 #@param {type: \"slider\", min: 0.0, max: 1.0, step: 0.1}\n",
    "max_delta = 1e-8 #@param {type:\"float\"}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cerința 1\n",
    "Implementați funcția **policy_iteration** pentru calculul politicii optime și a tabelului de utilitate așteptată pentru fiecare stare (celulă din grid) a labirintului. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_value(game, state, action, value_dict, gamma):\n",
    "    # calculate value for state\n",
    "    val = 0\n",
    "    for next_state, prob, reward in game.effects(state, action):\n",
    "        val += prob * (reward + gamma * value_dict[next_state])\n",
    "\n",
    "    return val\n",
    "\n",
    "def policy_iteration(game: Maze) -> Tuple[Dict[Tuple[int, int], int], Dict[Tuple[int, int], float]]:\n",
    "    v = {s: 0 for s in game.states}\n",
    "    policy = {s: choice(game.actions)\n",
    "              for s in game.states if not game.is_final(s)}\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        done = True\n",
    "        while True:\n",
    "            delta = 0\n",
    "            \n",
    "            #calculate expected value\n",
    "            for s in game.states:\n",
    "                if game.is_final(s):\n",
    "                    continue\n",
    "                old_value = v[s]\n",
    "                v[s] = get_value(game, s, policy[s], v, gamma)\n",
    "                delta = max(delta, abs(old_value - v[s]))\n",
    "            if delta < max_delta:\n",
    "                break\n",
    "        \n",
    "        #calculate policy\n",
    "        for s in game.states:\n",
    "            if game.is_final(s):\n",
    "                continue\n",
    "            old_action = policy[s]\n",
    "            best_value = -np.inf\n",
    "\n",
    "            #argmax in the future\n",
    "            for a in game.actions:\n",
    "                action_value = get_value(game, s, a, v, gamma)\n",
    "                if action_value > best_value:\n",
    "                    best_value = action_value\n",
    "                    policy[s] = a\n",
    "\n",
    "            if old_action != policy[s]:\n",
    "                done = False\n",
    "\n",
    "    return policy, v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cerința 2\n",
    "Implementați funcția **value_iteration** pentru calculul politicii optime și a tabelului de utilitate așteptată pentru fiecare stare (celulă din grid) a labirintului. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_iteration(game: Maze) -> Tuple[Dict[Tuple[int, int], int], Dict[Tuple[int, int], float]]:\n",
    "    v = {s: 0 for s in game.states}\n",
    "    policy = {s: choice(game.actions) for s in game.states if not game.is_final(s)}\n",
    "\n",
    "    done = False\n",
    "    while not done:\n",
    "        done = True  \n",
    "        delta = 0\n",
    "        for s in game.states:\n",
    "            if game.is_final(s):\n",
    "                continue\n",
    "            old_value = v[s]\n",
    "            v[s] = max(get_value(game, s, action, v, gamma) for action in game.actions)\n",
    "            delta = max(delta, abs(old_value - v[s]))\n",
    "        if delta < max_delta:\n",
    "                break\n",
    "\n",
    "        for s in game.states:\n",
    "            if game.is_final(s):\n",
    "                continue\n",
    "            best_action = None\n",
    "            best_value = -np.inf\n",
    "        \n",
    "            for action in game.actions:\n",
    "                action_value = get_value(game, s, action, v, gamma)\n",
    "                if action_value > best_value:\n",
    "                    best_value = action_value\n",
    "                    best_action = action\n",
    "\n",
    "            if policy[s] != best_action:\n",
    "                policy[s] = best_action\n",
    "                done = False \n",
    "\n",
    "    return policy, v\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U6CoJAktMV_I"
   },
   "source": [
    "## Evaluare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "lDueFUXSMUwL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy iteration:\n",
      "      |       |       |       |       |       |       |       |       |       |       |       |      \n",
      "      |  0.00 |  0.01 |  0.01 |  0.01 |  0.01 |  0.01 |  0.02 |  0.02 |  0.02 |  0.02 |  0.03 |       |      \n",
      "      |       |       |       |       |       |       |       |       |       |       |  0.03 |  0.03 |       |       |       |       |       |      \n",
      "      |       |  0.98 |  0.86 |  0.75 |  0.66 |  0.57 |       |       |       |       |  0.03 |  0.04 |  0.05 |  0.05 |  0.06 |  0.07 |  0.08 |      \n",
      "      |       |       |       |       |       |  0.50 |       |       |       |       |       |       |       |       |       |       |  0.09 |      \n",
      "      |       |       |       |       |       |  0.44 |  0.38 |  0.34 |  0.29 |  0.26 |  0.23 |  0.20 |  0.18 |  0.15 |  0.14 |  0.12 |  0.10 |      \n",
      "      |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |      \n",
      "┏━━━━━━━━━━━┓\n",
      "┃↑→→→→→→→→→↓┗┓\n",
      "┃A╺━━━━┳┳┳┓↓↓┗━━━━┓\n",
      "┃B←←←←←┣╋╋┫→→→→→→↓┃\n",
      "┣┳┳┳┳┓↑┗┻┻┻━━━━━╸↓┃\n",
      "┣╋╋╋╋┫↑←←←←←←←←←←←┃\n",
      "┗┻┻┻┻┻━━━━━━━━━━━━┛\n",
      "Value iteration:\n",
      "      |       |       |       |       |       |       |       |       |       |       |       |      \n",
      "      |  0.00 |  0.00 |  0.00 |  0.00 |  0.00 |  0.00 |  0.01 |  0.01 |  0.01 |  0.02 |  0.02 |       |      \n",
      "      |       |       |       |       |       |       |       |       |       |       |  0.03 |  0.03 |       |       |       |       |       |      \n",
      "      |       |  0.98 |  0.86 |  0.75 |  0.66 |  0.57 |       |       |       |       |  0.03 |  0.04 |  0.05 |  0.05 |  0.06 |  0.07 |  0.08 |      \n",
      "      |       |       |       |       |       |  0.50 |       |       |       |       |       |       |       |       |       |       |  0.09 |      \n",
      "      |       |       |       |       |       |  0.44 |  0.38 |  0.34 |  0.29 |  0.26 |  0.23 |  0.20 |  0.18 |  0.15 |  0.14 |  0.12 |  0.10 |      \n",
      "      |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |      \n",
      "┏━━━━━━━━━━━┓\n",
      "┃↑→→→→→→→→→↓┗┓\n",
      "┃A╺━━━━┳┳┳┓↓↓┗━━━━┓\n",
      "┃B←←←←←┣╋╋┫→→→→→→↓┃\n",
      "┣┳┳┳┳┓↑┗┻┻┻━━━━━╸↓┃\n",
      "┣╋╋╋╋┫↑←←←←←←←←←←←┃\n",
      "┗┻┻┻┻┻━━━━━━━━━━━━┛\n"
     ]
    }
   ],
   "source": [
    "#@title\n",
    "    \n",
    "game = Maze(MAP_NAME)\n",
    "\n",
    "print(\"Policy iteration:\")\n",
    "policy, v = policy_iteration(game)\n",
    "game.print_values(v)\n",
    "game.print_policy(policy)\n",
    "\n",
    "print(\"Value iteration:\")\n",
    "policy, v = value_iteration(game)\n",
    "game.print_values(v)\n",
    "game.print_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNn7A0noGBNa+cyDeN309Wg",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Laborator 6.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
